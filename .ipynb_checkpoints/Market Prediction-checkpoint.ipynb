{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Intro \n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/09/AI_applications_in_financial_services-565x613.png \"Logo Title Text 1\")\n",
    "\n",
    "- The Finance industry is an earlier pioneer of adopting AI, contrary to the belief that its the most risk averse\n",
    "- Banks have started to harness AI to meet ever-growing regulatory demands while minimizing the cost of human capital\n",
    "- Citigroup estimates that the biggest banks have doubled the number of people they employ to handle compliance and regulation, costing the banking industry 270 billion a year and accounting for 10 percent of its operating costs.\n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/10/AI_solution_deployment_blog_96_dpi-565x454.png \"Logo Title Text 1\")\n",
    "\n",
    "- Reducing costs is not abot labor arbitrage and offshore hiring. Its about automation now.\n",
    "- 90% of the worlds data collected in past 2 years. Never been a better time for this. \n",
    "- Resource-intensive, repetitive tasks, such as data entry and transaction processing, are well suited to automation and AI. \n",
    "- CFOs of big companies and startup entrepeneurs need to be looking for ways to use AI to improve FinTech (planning, budgeting and forecasting, financial reporting, operational accounting, allocations and adjustments, reconciliations, intercompany transactions)\n",
    "\n",
    "![alt text](https://bluenotes.anz.com/content/dam/bluenotes/images/articles/2016/June/sibsonrizzo_ai-bakermckenzie_infog2.png/_jcr_content/renditions/original \"Logo Title Text 1\")\n",
    "\n",
    "### The market for AI in financial services is expected to grow from 1.3 billion in 2017 to 7.4 billion in 2022, at a CAGR of 40.4%, according to Research and Markets. \n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*jsmP9AHF5c7_vBaFLpefsQ.png \"Logo Title Text 1\")\n",
    "\n",
    "## Problems with integrating AI\n",
    "\n",
    "![alt text](https://thefinancialbrand.com/wp-content/uploads/2017/02/barriers_to_digital_transformation_banking-565x443.png \"Logo Title Text 1\")\n",
    "\n",
    "- Legacy systems that do not communicate\n",
    "- Privacy concerns\n",
    "- Data silos\n",
    "- A lack of trained staff\n",
    "- The laborious effort of training supervised models\n",
    "- Lack of cultural alignment\n",
    "- Potential bias of machine learning\n",
    "- Deciding between cloud vendor, internal build, open source, or proprietary tech?\n",
    "\n",
    "![alt text](https://dashbouquet.com/assets/img/blog/AI-in-FinTech-Market-Map-Image.png \"Logo Title Text 1\")\n",
    "\n",
    "## Applications\n",
    "\n",
    "![alt text](https://qph.fs.quoracdn.net/main-qimg-fcb631ba245b7d74fab2f851fba7093d-c \"Logo Title Text 1\")\n",
    "\n",
    "#### Increasing Security\n",
    "\n",
    "![alt text](https://d279iyy6fmg6l4.cloudfront.net/blog/fraud-detection-in-banking.png \"Logo Title Text 1\")\n",
    "\n",
    "- Fraudalent behavior, suspicious transactions, potential future attacks. How can this be mitigated?\n",
    "- AI can analyze huge volumes of security data and scale to the size of a company as it grows\n",
    "- So much valuable company data is being stored online. More and more. \n",
    "-  Using machine learning, systems can detect unique activities or behaviors (“anomalies”) and flag them for security teams. \n",
    "- Given the incalculably high number of ways that security can be breached, genuinely “learning” systems will be a necessity in the five to ten years ahead.\n",
    "- According to a 2015 study by research firm Javelin Strategy, false declines, legitimate transactions that are wrongly rejected, account for 118 bln in losses for retailers. \n",
    "- A third of false decline cases result in lost customers, and in US alone they incur damage that is worth 13 times the value of actual fraud.\n",
    "-  By analyzing various data points, machine learning algorithms can detect fraudulent transactions that would go unnoticed by human analysts while improving the accuracy of real-time approvals and reducing false declines.\n",
    "\n",
    "![alt text](https://newsroom.mastercard.com/wp-content/uploads/2016/11/MasterCard-decision-intelligence-infographic.V.6_TwitterCards.png \"Logo Title Text 1\")\n",
    "\n",
    "- Mastercard recently launched Decision Intelligence technology. \n",
    "- Instead of limiting itself to predefined rules, DI gleans patterns from historical shopping and spending habits of cardholders to set a behavioral baseline against which it will compare and score each new transaction.\n",
    "\n",
    "![alt text](https://gigaom.com/wp-content/uploads/sites/1/2013/03/siftscience.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Sift Science collects data from more than 6,000 websites where its fraud detection solution is deployed. \n",
    "- This enables it to track and analyze data across multiple channels and devices\n",
    "\n",
    "#### Reducing Processing Times\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/2000/1*MfGMH7gnYgFd_NrLIUC7gA.png \"Logo Title Text 1\")\n",
    "\n",
    "- Processing receipts and other financial documentation is extremely time-consuming; \n",
    "- It requires the patience and perseverance of multiple resources and is one of those necessary tasks that’s often prone to human error.\n",
    "- https://www.parascript.com/receipt-capture/ does this\n",
    "\n",
    "#### Trading\n",
    "\n",
    "![alt text](http://www.turingfinance.com/wp-content/uploads/2013/11/Algorithmic-Trading-Systems-Conceptual.png \"Logo Title Text 1\")\n",
    "\n",
    "- Algorithmic trading involves the use of complex AI systems to make extremely fast trading decisions. ( originated in 70s)\n",
    "-  Algorithmic systems often making thousands or millions of trades in a day, hence the term “high-frequency trading” (HFT), which is considered to be a subset of algorithmic trading. \n",
    "- Most hedge funds and financial institutions do not openly disclose their AI approaches to trading (for good reason), but machine learning and deep learning are playing an increasingly important role in calibrating trading decisions in real time\n",
    "-  The stock market moves in response to myriad human-related factors that have nothing to do with ticker symbols, and the hope is that machine learning will be able to replicate and enhance human “intuition” of financial activity by discovering new trends and telling signals\n",
    "- Some popular hedge funds using AI include - Two Sigma, LLC, PDT Partners, DE Shaw, Man AHL, Citadel, Vatic Labs, Point72, Cubist etc.\n",
    "\n",
    "![alt text](https://cdn.sentient.ai/wp-content/uploads/2015/11/Creating_Genes_Slide_01.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Sentient Technologies, an AI company based in San Francisco that also runs a hedge fund, has developed an algorithm that ingests millions of data points to find trading patterns and forecast trends, which enable it to make successful stock trading decisions. \n",
    "- Sentient runs trillions of simulated trading scenarios created from the vast amounts of public data available online. \n",
    "- Squeeze 1,800 days of trading into a few minutes. \n",
    "- Successful trading strategies, which it calls “genes,” are then tested in live trading, where they evolve autonomously as they gain experience.\n",
    "\n",
    "![alt text](https://s3.fintastico.com/media/CACHE/images/numerai-screenshot_756/507ca3ac16b727303ec3f180bd343adf.jpg \"Logo Title Text 1\")\n",
    "\n",
    "- Numerai uses artificial intelligence to make trading decisions.\n",
    "- Instead of developing the algorithms themselves, they’ve outsourced the task to thousands of anonymous data scientists, who compete to create the best algorithms and win cryptocurrency for their efforts. \n",
    "- They share trading data with the scientists in a way that prevents them from replicating the fund’s trades while allowing them to build models for better trades.\n",
    "\n",
    "#### Credit Lending\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/richardharris-feedzai-161117114315/95/using-machine-learning-ai-to-enhance-fraud-detection-21-638.jpg?cb=1479383034 \"Logo Title Text 1\")\n",
    "\n",
    "- Machine learning algorithms can be trained on millions of examples of consumer data (age, job, marital status, etc…) and financial lending or insurance results (did this person default, pay back the loan on time, get in a car accident, etc…?).\n",
    "- Trends can be continuously analyzed to detect trends that might influence lending and insuring into the future (are more and more young people in a certain state getting in car accidents? Are there increasing rates of default among a specific demographic population over the last 15 years?\n",
    "- Traditional systems relied on historical data like transaction history, credit history and income growth over years to understand the risk associated with every loan extended. \n",
    "- This results in inconsistent estimates as historical data is not always an accurate standard to predict future behavior.\n",
    "- Machine learning allows analysis of real-time data of recent transactions, market conditions and even latest news to identify potential risks in offering credit. \n",
    "- With the help of predictive analytics, an ML algorithm can analyze petabytes of data to understand micro activities and assess the behavior of parties to identify a possible fraud. \n",
    "- This is something impossible for human investors to perform manually.\n",
    "- Zestfinance does this https://www.zestfinance.com/zaml \n",
    "\n",
    "#### Portfolio Management\n",
    "\n",
    "![alt text](https://blogs.thomsonreuters.com/financial-risk/wp-content/uploads/sites/12/2017/12/1-What-wealth-managers-need-to-know-about-AI-12-Dec-17.gif \"Logo Title Text 1\")\n",
    "\n",
    "- The term “robo-advisor” was essentially unheard-of just five years ago, but it is now commonplace in the financial landscape. \n",
    "- These are algorithms built to calibrate a financial portfolio to the goals and risk tolerance of the user.\n",
    "- Users enter their goals (for example, retiring at age 65 with 250,000.00 in savings), age, income, and current financial assets. \n",
    "- The robo-advisor then spreads investments across asset classes and financial instruments in order to reach the user’s goals.\n",
    "-  The system then calibrates to changes in the user’s goals and to real-time changes in the market, aiming always to find the best fit for the user’s original goals. \n",
    "- Robo-advisors have gained significant traction with millennial consumers who don’t need a physical advisor to feel comfortable investing\n",
    "- Similarly, AI-enabled personal finance intelligence applications are helping consumers manage their finances, analyze spending, automate tax form filing, and make financial recommendations with a business model not predicated to generating fees from investments.\n",
    "- Responsive.ai is doing this http://alpha.responsive.ai/ \n",
    "\n",
    "## Theory\n",
    "\n",
    "### Data Points to Use\n",
    "\n",
    "- Tweets about a company (good/bad)\n",
    "- Reddit Posts (good/bad)\n",
    "- News headlines about a company (good/bad)\n",
    "- Past Prices\n",
    "- All sorts of social media, blog posts\n",
    "- All sorts of financial metadata (dividends, financial reports, etc) \n",
    "\n",
    "#### Regression Problem vs Classification Problem? \n",
    "\n",
    "![alt text](https://searchengineland.com/figz/wp-content/seloads/2016/07/class-regress.png \"Logo Title Text 1\")\n",
    "\n",
    "- We can think of it as a regression model, i.e whats the next data point in a time series? \n",
    "- We can also think of it as a classsificiation problem, i.e will the stock go up or down tomorrow? Buy or sell? \n",
    "- If we want to think of it as a regression problem, we can use a single data point to build the line of best fit.\n",
    "- If we want to use multiple data points, we can use numerical data to create a multivariate regression model. \n",
    "- If we want to use a classification model using a single data point, we'd just learn the mapping between the input (tweets, posts, comments on a given day) and the output (good/bad). We would be able to say that for a given day, the majority of the sentiment for a stack was either good or bad. So for every date givem, our algorithm would learn overall whether or not a stock did well or not. Then given a new date, we could classify it as good/bad. \n",
    "- If we want to combine both sentiment and numerical data i.e prices, we would just use the overall sentiment output of a given date (0 or 1) as an additional feature in our numerical dataset. \n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "- A linear regression line has an equation of the form Y = a + bX, where X is the explanatory variable and Y is the dependent variable. The slope of the line is b, and a is the intercept (the value of y when x = 0).\n",
    "\n",
    "![alt text](http://developer.rhino3d.com/images/linear-regression-01.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.linear_model' has no attribute 'SupportVectorMachine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-53fa3490fe17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create linear regression object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupportVectorMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Train the model using the training sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.linear_model' has no attribute 'SupportVectorMachine'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "prices = datasets.load_boston()\n",
    "\n",
    "# # Use only one feature\n",
    "# prices_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# # Split the data into training/testing sets\n",
    "# prices_X_train = prices_X[:-20]\n",
    "# prices_X_test = prices_X[-20:]\n",
    "\n",
    "# # Split the targets into training/testing sets\n",
    "# prices_y_train = prices.target[:-20]\n",
    "# prices_y_test = prices.target[-20:]\n",
    "\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "print(X_full.shape)\n",
    "print(y_full.shape)\n",
    "prices_X_train = X_full[:-20]\n",
    "prices_X_test = X_full[-20:]\n",
    "\n",
    "prices_y_train = y_full[:-20]\n",
    "prices_y_test = y_full[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.SupportVectorMachine()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(prices_X_train, prices_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "prices_y_pred = regr.predict(prices_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks\n",
    "\n",
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*6zJ2ZUUPIOC8nhGqTr3yBQ.jpeg  \"Logo Title Text 1\")\n",
    "\n",
    "![alt text](https://i.ytimg.com/vi/kMLl-TKaEnc/maxresdefault.jpg \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima price dataset\n",
    "dataset = datasets.load_boston()\n",
    "type(dataset)\n",
    "# split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:8]\n",
    "# Y = dataset[:,8]\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "print(X_full.shape)\n",
    "print(y_full.shape)\n",
    "prices_X_train = X_full[:-20]\n",
    "print(len(prices_X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n",
      "Epoch 1/150\n",
      "506/506 [==============================] - 2s 3ms/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 3/150\n",
      "506/506 [==============================] - 0s 182us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 4/150\n",
      "506/506 [==============================] - 0s 178us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 5/150\n",
      "506/506 [==============================] - 0s 184us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 6/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 7/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 8/150\n",
      "506/506 [==============================] - 0s 187us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 9/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 10/150\n",
      "506/506 [==============================] - 0s 177us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 11/150\n",
      "506/506 [==============================] - 0s 197us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 12/150\n",
      "506/506 [==============================] - 0s 198us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 13/150\n",
      "506/506 [==============================] - 0s 190us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 14/150\n",
      "506/506 [==============================] - 0s 197us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 15/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 16/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 17/150\n",
      "506/506 [==============================] - 0s 182us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 18/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 19/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 20/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 21/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 22/150\n",
      "506/506 [==============================] - 0s 178us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 23/150\n",
      "506/506 [==============================] - 0s 191us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 24/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 25/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 26/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 27/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 28/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 29/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 30/150\n",
      "506/506 [==============================] - 0s 186us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 31/150\n",
      "506/506 [==============================] - 0s 192us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 32/150\n",
      "506/506 [==============================] - 0s 182us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 33/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 34/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 35/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 36/150\n",
      "506/506 [==============================] - 0s 199us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 37/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 38/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 39/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 40/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 41/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 42/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 43/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 44/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 45/150\n",
      "506/506 [==============================] - 0s 186us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 46/150\n",
      "506/506 [==============================] - 0s 193us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 47/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 48/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 49/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 50/150\n",
      "506/506 [==============================] - 0s 190us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 51/150\n",
      "506/506 [==============================] - 0s 186us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 52/150\n",
      "506/506 [==============================] - 0s 187us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 53/150\n",
      "506/506 [==============================] - 0s 192us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 54/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 55/150\n",
      "506/506 [==============================] - 0s 194us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 56/150\n",
      "506/506 [==============================] - 0s 192us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 57/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 58/150\n",
      "506/506 [==============================] - 0s 193us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 59/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 60/150\n",
      "506/506 [==============================] - 0s 175us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 61/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 62/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 63/150\n",
      "506/506 [==============================] - 0s 195us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 64/150\n",
      "506/506 [==============================] - 0s 191us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 65/150\n",
      "506/506 [==============================] - 0s 194us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 66/150\n",
      "506/506 [==============================] - 0s 190us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 67/150\n",
      "506/506 [==============================] - 0s 171us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 68/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 69/150\n",
      "506/506 [==============================] - 0s 203us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 70/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 71/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 72/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 73/150\n",
      "506/506 [==============================] - 0s 175us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 74/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 75/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 76/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 77/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 78/150\n",
      "506/506 [==============================] - 0s 199us/step - loss: 363.1859 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150\n",
      "506/506 [==============================] - 0s 178us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 80/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 81/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 82/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 83/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 84/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 85/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 86/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 87/150\n",
      "506/506 [==============================] - 0s 178us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 88/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 89/150\n",
      "506/506 [==============================] - 0s 175us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 90/150\n",
      "506/506 [==============================] - 0s 175us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 91/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 92/150\n",
      "506/506 [==============================] - 0s 175us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 93/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 94/150\n",
      "506/506 [==============================] - 0s 178us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 95/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 96/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 97/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 98/150\n",
      "506/506 [==============================] - 0s 194us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 99/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 100/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 101/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 102/150\n",
      "506/506 [==============================] - 0s 184us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 103/150\n",
      "506/506 [==============================] - 0s 184us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 104/150\n",
      "506/506 [==============================] - 0s 195us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 105/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 106/150\n",
      "506/506 [==============================] - 0s 191us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 107/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 108/150\n",
      "506/506 [==============================] - 0s 184us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 109/150\n",
      "506/506 [==============================] - 0s 187us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 110/150\n",
      "506/506 [==============================] - 0s 172us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 111/150\n",
      "506/506 [==============================] - 0s 183us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 112/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 113/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 114/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 115/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 116/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 117/150\n",
      "506/506 [==============================] - 0s 176us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 118/150\n",
      "506/506 [==============================] - 0s 177us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 119/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 120/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 121/150\n",
      "506/506 [==============================] - 0s 196us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 122/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 123/150\n",
      "506/506 [==============================] - 0s 192us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 124/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 125/150\n",
      "506/506 [==============================] - 0s 193us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 126/150\n",
      "506/506 [==============================] - 0s 189us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 127/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 128/150\n",
      "506/506 [==============================] - 0s 197us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 129/150\n",
      "506/506 [==============================] - 0s 182us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 130/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 131/150\n",
      "506/506 [==============================] - 0s 179us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 132/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 133/150\n",
      "506/506 [==============================] - 0s 180us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 134/150\n",
      "506/506 [==============================] - 0s 197us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 135/150\n",
      "506/506 [==============================] - 0s 195us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 136/150\n",
      "506/506 [==============================] - 0s 190us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 137/150\n",
      "506/506 [==============================] - 0s 184us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 138/150\n",
      "506/506 [==============================] - 0s 174us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 139/150\n",
      "506/506 [==============================] - 0s 182us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 140/150\n",
      "506/506 [==============================] - 0s 182us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 141/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 142/150\n",
      "506/506 [==============================] - 0s 195us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 143/150\n",
      "506/506 [==============================] - 0s 197us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 144/150\n",
      "506/506 [==============================] - 0s 185us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 145/150\n",
      "506/506 [==============================] - 0s 170us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 146/150\n",
      "506/506 [==============================] - 0s 181us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 147/150\n",
      "506/506 [==============================] - 0s 195us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 148/150\n",
      "506/506 [==============================] - 0s 198us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 149/150\n",
      "506/506 [==============================] - 0s 188us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "Epoch 150/150\n",
      "506/506 [==============================] - 0s 193us/step - loss: 363.1859 - acc: 0.0000e+00\n",
      "506/506 [==============================] - 0s 45us/step\n",
      "\n",
      "acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima price dataset\n",
    "dataset = datasets.load_boston()\n",
    "# split into input (X) and output (Y) variables\n",
    "# X = dataset[:,0:8]\n",
    "# Y = dataset[:,8]\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "print(X_full.shape)\n",
    "print(y_full.shape)\n",
    "X = X_full\n",
    "Y = y_full\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=13, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "- A forecast predicts future events.\n",
    "\n",
    "- A reinforcement learning agent optimizes future outcomes.\n",
    "\n",
    "https://doctorj.gitlab.io/sairen/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnregisteredEnv",
     "evalue": "No registered env with id: sairen-v0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/tensorflow-gpu/lib/python3.5/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mspec\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_specs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sairen-v0'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnregisteredEnv\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-68e060753e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sairen-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow-gpu/lib/python3.5/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow-gpu/lib/python3.5/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Making new env: %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# We used to have people override _reset/_step rather than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tensorflow-gpu/lib/python3.5/site-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mspec\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeprecatedEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Env {} not found (valid versions include {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnregisteredEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No registered env with id: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnregisteredEnv\u001b[0m: No registered env with id: sairen-v0"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('sairen-v0')\n",
    "for i_episode in xrange(20):\n",
    "    observation = env.reset()\n",
    "    for t in xrange(100):\n",
    "        env.render()\n",
    "        print (observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print (\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sairen'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6e282870d42e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msairen\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMarketEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"\"\"Create a market environment, instantiate a random agent, and run the agent for one episode.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sairen'"
     ]
    }
   ],
   "source": [
    "from sairen import MarketEnv\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Create a market environment, instantiate a random agent, and run the agent for one episode.\"\"\"\n",
    "    env = MarketEnv(\"AAPL\", episode_steps=20)   # Apple stock, 1-second bars by default\n",
    "    agent = RandomAgent(env.action_space)       # Actions are continuous from -1 = go short to +1 = go long.  0 is go flat.  Sets absolute target position.\n",
    "    observation = env.reset()       # An observation is a numpy float array, values: time, bid, bidsize, ask, asksize, last, lastsize, lasttime, open, high, low, close, vwap, volume, open_interest, position, unrealized_gain\n",
    "    done = False\n",
    "    total_reward = 0.0              # Reward is the profit realized when a trade closes\n",
    "    while not done:\n",
    "        env.render()\n",
    "        observation, reward, done, info = env.step(agent.act(observation))\n",
    "        total_reward += reward\n",
    "\n",
    "    print('\\nTotal profit: {:.2f}'.format(total_reward))        # Sairen will automatically (try to) cancel open orders and close positions on exit\n",
    "\n",
    "\n",
    "class RandomAgent:\n",
    "    \"\"\"Agent that randomly samples the action space.\"\"\"\n",
    "    def __init__(self, action_space):\n",
    "        \"\"\":param gym.Space action_space: The Space to sample from.\"\"\"\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, observation):\n",
    "        \"\"\":Return: a random action from the action space.\"\"\"\n",
    "        return self.action_space.sample()       # Here the observation is ignored, but a less-random agent would want it.\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Time! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
